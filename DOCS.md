# drone-fleet
Example configuration in your .drone.yml file:

[![Build Status](https://drone.crisidev.org/api/badges/crisidev/drone-fleet/status.svg)](https://drone.crisidev.org/crisidev/drone-fleet)
[![](https://badge.imagelayers.io/crisidev/drone-fleet:latest.svg)](https://imagelayers.io/?images=crisidev/drone-fleet:latest 'Get your own badge on imagelayers.io')

```yaml
deploy:
  fleet:
    image: crisidev/drone-fleet
    endpoint:
    units:
      - fleet/unit.service
    tunnel: user@bastion.mydomain.com:2222
    scale: 4
    timeout: 2
    sleep: 10
    rolling_sleep: 120
    destroy: false
    stop: true
```

## Parameters
Mandatory parameters are <u>underlined</u>

* <u><b>image:</b></u> drone-fleet plugin docker image
* <u><b>endpoint:</b></u> etcd endpoint for fleetctl commands, can be also specified to the drone container using DRONE_ETCD_ENDPOINT env variable
* <b>units:</b> list of unit files to run on the cluster, files need to exist in the git repository, default repository name
* <b>scale:</b> number of instances of units you want to start (see [rolling update notes](DOCS.md#rolling-update)), default 1
* <b>tunnel:</b> create a SSH tunnel to reach the etcd cluster (see [tunneling notes](DOCS.md#tunneling)), default empty
* <b>destroy:</b> destroy units during update (see [deploy method notes](DOCS.md#deploy-method)), default false
* <b>stop:</b> do not start units during update (see [deploy method notes](DOCS.md#deploy-method)), default false
* <b>sleep:</b> fleetctl commands timeout in seconds, default 5
* <b>rolling_sleep:</b> timeout between every instances deploy for scaled units, default 120
* <b>timeout:</b> sleep seconds between fleetctl commands, default 10

## Notes
### Deploy Method
Deploy is controlled by <b>destroy</b> and <b>stop</b> parameters. 

* Normal deploy consist in stop of the unit and restart of it.
* When destroy is true, the unit will be destroyed and removed from systemd. This is useful when you have changed the unit file content or if you want a full deployment cycle.
* When stop is true, units are only stopped and there is no restart. This can be combined with destroy to fully remove the unit from the cluster. Note: to troubleshoot you should not use destroy with stop, since systemd logs can be lost.
* After every action (stop, destroy, start), the plugin sleeps for n seconds (default 10 ) to allow fleetd and systemd to do their job.

### Rolling Update
When scale is set to more than 1, the plugin will try to run a rolling update and will allow some time for load-balancers / proxies / etc.. to update. 

Unit files need to be named accordingly with systemd scalable units format, like <b>myunit@.service)</b> (more info [CoreOS docs](https://coreos.com/fleet/docs/latest/launching-containers-fleet.html).

Units will be started from index 0 and the plugin will deploy n instances per unit (ex: scale:2 -> myunit@0.service, myunit@1.service).

The rolling update process follows this scheme:

```bash
for every unit in unit list:
  stop unit
  if destroy:
    destroy unit
  start unit
  sleep seconds
```

Rolling update sleep time is controlled by parameter <b>rolling_sleep</b>  (default 120 sec)

### Tunneling
If the Etcd endpoint is not directly reachable from your Drone nodes, you can use the parameter <b>tunnel</b> to specify a bastion host used by fleetctl to SSH to. The format of this parameter is
[user@]host[:port], if port and user are not specified, we assume root and 22.

The plugin authenticates to your server using a per-repository SSH key generated by Drone. You can find the public key in your repository settings in Drone. You will need to copy / paste this key into your deploy user `~/.ssh/authorized_keys` file on your remote machine.

The SSH private key is gathered from Drone and saved in `/root/.ssh/id_rsa`. And ssh-agent is spawned, SSH_AUTH_SOCK variable is populated and the private key added to the agent.
Fleetctl supports only ssh-agent based key authentication and this trick allows the plugin container to tunnel via SSH.

## TODO
### Fix hack used to read the ssh-agent socket
SSH agent socket is read from the stdout of the executed command. If the output line contains SSH_AUTH_SOCK, than various splits and slice manipulations are performed and the variable added to os.Env. I need to find a better way to handle ssh-agent environment variables since this is a horrendous hack.

### Find a solution for rolling-back fleet deploy
This will need to have an associated git workflow and deploy using proper and automatic versioning.
